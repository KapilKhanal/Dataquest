{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lending Club releases data for all of the approved and declined loan applications periodically on their [website](https://www.lendingclub.com/info/download-data.action). You can select a few different year ranges to download the datasets (in CSV format) for both approved and declined loans.\n",
    "\n",
    "You'll also find a data dictionary (in XLS format) which contains information on the different column names towards the bottom of the page. We recommend downloading the data dictionary to so you can refer to it whenever you want to learn more about what a column represents in the datasets. Here's a link to the data dictionary file hosted on [Google Drive](https://docs.google.com/spreadsheets/d/191B2yJ4H1ZPXq0_ByhUgWMFZOYem5jFz0Y3by_7YBY4/edit).\n",
    "\n",
    "Before diving into the datasets themselves, let's get familiar with the data dictionary. The LoanStats sheet describes the approved loans datasets and the RejectStats describes the rejected loans datasets. Since rejected applications don't appear on the Lending Club marketplace and aren't available for investment, we'll be focusing on data on approved loans only.\n",
    "\n",
    "The approved loans datasets contain information on current loans, completed loans, and defaulted loans. Let's now define the problem statement for this machine learning project:\n",
    "\n",
    " - Can we build a machine learning model that can accurately predict if a borrower will pay off their loan on time or not?\n",
    "\n",
    "We'll focus on approved loans data from 2007 to 2011, since a good number of the loans have already finished. In the datasets for later years, many of the loans are current and still being paid off.\n",
    "\n",
    "We have reduced the size of the dataset to make it easier to work with, by:\n",
    "\n",
    " - removing the `desc` column:\n",
    "   - which contains a long text explanation for each loan\n",
    " - removing the `url` column:\n",
    "   - which contains a link to each loan on Lending Club which can only be accessed with an investor account\n",
    " - removing all columns containing more than 50% missing values:\n",
    "   - which allows us to move faster since we can spend less time trying to fill these values\n",
    "\n",
    "Before we can start doing machine learning, we need to define what features we want to use and which column repesents the target column we want to predict. Let's start by reading in the dataset and exploring it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otto/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                1077501\n",
      "member_id                      1.2966e+06\n",
      "loan_amnt                            5000\n",
      "funded_amnt                          5000\n",
      "funded_amnt_inv                      4975\n",
      "term                            36 months\n",
      "int_rate                           10.65%\n",
      "installment                        162.87\n",
      "grade                                   B\n",
      "sub_grade                              B2\n",
      "emp_title                             NaN\n",
      "emp_length                      10+ years\n",
      "home_ownership                       RENT\n",
      "annual_inc                          24000\n",
      "verification_status              Verified\n",
      "issue_d                          Dec-2011\n",
      "loan_status                    Fully Paid\n",
      "pymnt_plan                              n\n",
      "purpose                       credit_card\n",
      "title                            Computer\n",
      "zip_code                            860xx\n",
      "addr_state                             AZ\n",
      "dti                                 27.65\n",
      "delinq_2yrs                             0\n",
      "earliest_cr_line                 Jan-1985\n",
      "inq_last_6mths                          1\n",
      "open_acc                                3\n",
      "pub_rec                                 0\n",
      "revol_bal                           13648\n",
      "revol_util                          83.7%\n",
      "total_acc                               9\n",
      "initial_list_status                     f\n",
      "out_prncp                               0\n",
      "out_prncp_inv                           0\n",
      "total_pymnt                       5863.16\n",
      "total_pymnt_inv                   5833.84\n",
      "total_rec_prncp                      5000\n",
      "total_rec_int                      863.16\n",
      "total_rec_late_fee                      0\n",
      "recoveries                              0\n",
      "collection_recovery_fee                 0\n",
      "last_pymnt_d                     Jan-2015\n",
      "last_pymnt_amnt                    171.62\n",
      "last_credit_pull_d               Jun-2016\n",
      "collections_12_mths_ex_med              0\n",
      "policy_code                             1\n",
      "application_type               INDIVIDUAL\n",
      "acc_now_delinq                          0\n",
      "chargeoff_within_12_mths                0\n",
      "delinq_amnt                             0\n",
      "pub_rec_bankruptcies                    0\n",
      "tax_liens                               0\n",
      "Name: 0, dtype: object\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loans_2007 = pd.read_csv(\"loans_2007.csv\")\n",
    "loans_2007.drop_duplicates()\n",
    "print(loans_2007.iloc[0])\n",
    "print(loans_2007.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First group of columns\n",
    "\n",
    "The Dataframe contains many columns and can be cumbersome to try to explore all at once. Let's break up the columns into 3 groups of 18 columns and use the data dictionary to become familiar with what each column represents. As you understand each feature, you want to pay attention to any features that:\n",
    "\n",
    " - leak information from the future (after the loan has already been funded)\n",
    " - don't affect a borrower's ability to pay back a loan (e.g. a randomly generated ID value by Lending Club)\n",
    " - formatted poorly and need to be cleaned up\n",
    " - require more data or a lot of processing to turn into a useful feature\n",
    " - contain redundant information\n",
    " \n",
    "After analyzing each column, we can conclude that the following features need to be removed:\n",
    "\n",
    " - `id`: randomly generated field by Lending Club for unique identification purposes only\n",
    " - `member_id`: also a randomly generated field by Lending Club for unique identification purposes only\n",
    " - `funded_amnt`: leaks data from the future (after the loan is already started to be funded)\n",
    " - `funded_amnt_inv`: also leaks data from the future (after the loan is already started to be funded)\n",
    " - `grade`: contains redundant information as the interest rate column (`int_rate)`\n",
    " - `sub_grade`: also contains redundant information as the interest rate column (`int_rate`)\n",
    " - `emp_title`: requires other data and a lot of processing to potentially be useful\n",
    " - `issue_d`: leaks data from the future (after the loan is already completed funded)\n",
    "\n",
    "Recall that Lending Club assigns a grade and a sub-grade based on the borrower's interest rate. While the grade and sub_grade values are categorical, the `int_rate` column contains continuous values, which are better suited for machine learning.\n",
    "\n",
    "Let's now drop these columns from the Dataframe before moving onto the next group of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop([\"id\", \"member_id\", \"funded_amnt\", \"funded_amnt_inv\", \"grade\", \"sub_grade\", \"emp_title\", \"issue_d\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd group of columns\n",
    "\n",
    "Within this group of columns, we need to drop the following columns:\n",
    "\n",
    " - `zip_code`: redundant with the `addr_state` column since only the first 3 digits of the 5 digit zip code are visible (which only can be used to identify the state the borrower lives in)\n",
    " - `out_prncp`: leaks data from the future, (after the loan already started to be paid off)\n",
    " - `out_prncp_inv`: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - `total_pymnt`: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - `total_pymnt_inv`: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - `total_rec_prncp`: also leaks data from the future, (after the loan already started to be paid off)\n",
    "\n",
    "- The `out_prncp` and `out_prncp_inv` both describe the outstanding principal amount for a loan, which is the remaining amount the borrower still owes. These 2 columns as well as the `total_pymnt` column describe properties of the loan after it's fully funded and started to be paid off. This information isn't available to an investor before the loan is fully funded and we don't want to include it in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop([\"zip_code\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\", \"total_pymnt_inv\", \"total_rec_prncp\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd group of columns\n",
    "\n",
    "In the last group of columns, we need to drop the following columns:\n",
    "\n",
    " - `total_rec_int`: leaks data from the future, (after the loan already started to be paid off),\n",
    " - `total_rec_late_fee`: also leaks data from the future, (after the loan already started to be paid off),\n",
    " - `recoveries`: also leaks data from the future, (after the loan already started to be paid off),\n",
    " - `collection_recovery_fee`: also leaks data from the future, (after the loan already started to be paid off),\n",
    " - `last_pymnt_d`: also leaks data from the future, (after the loan already started to be paid off),\n",
    " - `last_pymnt_amnt`: also leaks data from the future, (after the loan already started to be paid off).\n",
    "\n",
    "All of these columns leak data from the future, meaning that they're describing aspects of the loan after it's already been fully funded and started to be paid off by the borrower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                            5000\n",
      "term                            36 months\n",
      "int_rate                           10.65%\n",
      "installment                        162.87\n",
      "emp_length                      10+ years\n",
      "home_ownership                       RENT\n",
      "annual_inc                          24000\n",
      "verification_status              Verified\n",
      "loan_status                    Fully Paid\n",
      "pymnt_plan                              n\n",
      "purpose                       credit_card\n",
      "title                            Computer\n",
      "addr_state                             AZ\n",
      "dti                                 27.65\n",
      "delinq_2yrs                             0\n",
      "earliest_cr_line                 Jan-1985\n",
      "inq_last_6mths                          1\n",
      "open_acc                                3\n",
      "pub_rec                                 0\n",
      "revol_bal                           13648\n",
      "revol_util                          83.7%\n",
      "total_acc                               9\n",
      "initial_list_status                     f\n",
      "last_credit_pull_d               Jun-2016\n",
      "collections_12_mths_ex_med              0\n",
      "policy_code                             1\n",
      "application_type               INDIVIDUAL\n",
      "acc_now_delinq                          0\n",
      "chargeoff_within_12_mths                0\n",
      "delinq_amnt                             0\n",
      "pub_rec_bankruptcies                    0\n",
      "tax_liens                               0\n",
      "Name: 0, dtype: object\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "loans_2007 = loans_2007.drop([\"total_rec_int\", \"total_rec_late_fee\", \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_d\", \"last_pymnt_amnt\"], axis=1)\n",
    "print(loans_2007.iloc[0])\n",
    "print(loans_2007.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Column\n",
    "\n",
    "Just by becoming familiar with the columns in the dataset, we were able to reduce the number of columns from 52 to 32 columns. We now need to decide on a target column that we want to use for modeling.\n",
    "\n",
    "We should use the `loan_status` column, since it's the only column that directly describes if a loan was paid off on time, had delayed payments, or was defaulted on the borrower. \n",
    "\n",
    "Currently, this column contains text values and we need to convert it to a numerical one for training a model. \n",
    "\n",
    "Let's explore the different values in this column and come up with a strategy for converting the values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Paid                                             33136\n",
      "Charged Off                                             5634\n",
      "Does not meet the credit policy. Status:Fully Paid      1988\n",
      "Current                                                  961\n",
      "Does not meet the credit policy. Status:Charged Off      761\n",
      "Late (31-120 days)                                        24\n",
      "In Grace Period                                           20\n",
      "Late (16-30 days)                                          8\n",
      "Default                                                    3\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans_2007['loan_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification\n",
    "\n",
    "There are 8 different possible values for the `loan_status` column. \n",
    "\n",
    "You can read about most of the different loan statuses on the Lending Clube [website](https://help.lendingclub.com/hc/en-us/articles/215488038-What-do-the-different-Note-statuses-mean-). \n",
    "\n",
    "The two values that start with \"Does not meet the credit policy\" aren't explained unfortunately. \n",
    "\n",
    "A quick Google search takes us to explanations from the lending community [here](https://forum.lendacademy.com/?topic=2427.msg20813#msg20813).\n",
    "\n",
    "From the investor's perspective, we're interested in trying to predict which loans will be paid off on time and which ones won't be. Only the `Fully Paid` and `Charged Off` values describe the final outcome of the loan. The other values describe loans that are still on going and where the jury is still out on if the borrower will pay back the loan on time or not. While the `Default` status resembles the `Charged Off` status, in Lending Club's eyes, loans that are charged off have essentially no chance of being repaid while default ones have a small chance. You can read about the difference here.\n",
    "\n",
    "Since we're interested in being able to predict which of these 2 values a loan will fall under, we can treat the problem as a binary classification one. Let's remove all the loans that don't contain either `Fully Paid` and `Charged Off` as the loan's status and then transform the `Fully Paid` values to `1` for the positive case and the `Charged Off` values to `0` for the negative case. While there are a few different ways to transform all of the values in a column, we'll use the Dataframe method `replace`. \n",
    "\n",
    "We need to keep in mind is the class imbalance between the positive and negative cases. While there are 33,136 loans that have been fully paid off, there are only 5,634 that were charged off. This class imbalance is a common problem in binary classification and during training, the model ends up having a strong bias towards predicting the class with more observations in the training set and will rarely predict the class with less observations. The stronger the imbalance, the more biased the model becomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007[(loans_2007['loan_status'] == \"Fully Paid\") | (loans_2007['loan_status'] == \"Charged Off\")]\n",
    "\n",
    "status_replace = {\n",
    "    \"loan_status\" : {\n",
    "        \"Fully Paid\": 1,\n",
    "        \"Charged Off\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "loans_2007 = loans_2007.replace(status_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Single Value Columns\n",
    "\n",
    "To wrap up this mission, let's look for any columns that contain only one unique value and remove them. These columns won't be useful for the model since they don't add any information to each loan application. In addition, removing these columns will reduce the number of columns we'll need to explore further in the next mission.\n",
    "\n",
    "We'll need to compute the number of unique values in each column and drop the columns that contain only one unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pymnt_plan', 'initial_list_status', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'tax_liens']\n"
     ]
    }
   ],
   "source": [
    "orig_columns = loans_2007.columns\n",
    "drop_columns = []\n",
    "for col in orig_columns:\n",
    "    col_series = loans_2007[col].dropna().unique()\n",
    "    if len(col_series) == 1:\n",
    "        drop_columns.append(col)\n",
    "loans_2007 = loans_2007.drop(drop_columns, axis=1)\n",
    "print(drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Features\n",
    "\n",
    "We've exported the Dataframe from the end of the last mission to a CSV file named `filtered_loans_2007.csv` to differentiate the file with the loans_2007.csv we used in the last mission. In this mission, we'll prepare the data for machine learning by focusing on handling missing values, converting categorical columns to numeric columns, and removing any other extraneous columns we encounter throughout this process.\n",
    "\n",
    "This is because the mathematics underlying most machine learning models assumes that the data is numerical and contains no missing values. To reinforce this requirement, scikit-learn will return an error if you try to train a model using data that contain missing values or non-numeric values when working with models like linear regression and logistic regression.\n",
    "\n",
    "Let's start by computing the number of missing values and come up with a strategy for handling them. Then, we'll focus on the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_length              1036\n",
      "title                     11\n",
      "revol_util                50\n",
      "last_credit_pull_d         2\n",
      "pub_rec_bankruptcies     697\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loans = pd.read_csv('filtered_loans_2007.csv')\n",
    "null_counts = loans.isnull().sum()\n",
    "print(null_counts[null_counts>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    0.939438\n",
      "1.0    0.042456\n",
      "NaN    0.017978\n",
      "2.0    0.000129\n",
      "Name: pub_rec_bankruptcies, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(loans.pub_rec_bankruptcies.value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values \n",
    "\n",
    "We'll keep emp_length as it's often used in calculating risk on loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     11\n",
      "float64    10\n",
      "int64       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "loans = loans.drop(\"pub_rec_bankruptcies\", axis=1)\n",
    "loans = loans.dropna(axis=0)\n",
    "print(loans.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                     36 months\n",
      "int_rate                    10.65%\n",
      "emp_length               10+ years\n",
      "home_ownership                RENT\n",
      "verification_status       Verified\n",
      "purpose                credit_card\n",
      "title                     Computer\n",
      "addr_state                      AZ\n",
      "earliest_cr_line          Jan-1985\n",
      "revol_util                   83.7%\n",
      "last_credit_pull_d        Jun-2016\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Text columns\n",
    "\n",
    "object_columns_df = loans.select_dtypes(include=[\"object\"])\n",
    "print(object_columns_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Text Columns\n",
    "\n",
    "Some of the columns seem like they represent categorical values, but we should confirm by checking the number of unique values in those columns:\n",
    "\n",
    " - home_ownership: home ownership status, can only be 1 of 4 categorical values according to the data dictionary,\n",
    " - verification_status: indicates if income was verified by Lending Club,\n",
    " - emp_length: number of years the borrower was employed upon time of application,\n",
    " - term: number of payments on the loan, either 36 or 60,\n",
    " - addr_state: borrower's state of residence,\n",
    " - purpose: a category provided by the borrower for the loan request,\n",
    " - title: loan title provided the borrower,\n",
    "\n",
    "There are also some columns that represent numeric values, that need to be converted:\n",
    "\n",
    " - int_rate: interest rate of the loan in %,\n",
    " - revol_util: revolving line utilization rate or the amount of credit the borrower is using relative to all available credit, read more here.\n",
    "\n",
    "Based on the first row's values for purpose and title, it seems like these columns could reflect the same information. Let's explore the unique value counts separately to confirm if this is true.\n",
    "\n",
    "Lastly, some of the columns contain date values that would require a good amount of feature engineering for them to be potentially useful:\n",
    "\n",
    " - earliest_cr_line: The month the borrower's earliest reported credit line was opened,\n",
    " - last_credit_pull_d: The most recent month Lending Club pulled credit for this loan.\n",
    "\n",
    "Since these date features require some feature engineering for modeling purposes, let's remove these date columns from the Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First five categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENT        18112\n",
      "MORTGAGE    16686\n",
      "OWN          2778\n",
      "OTHER          96\n",
      "NONE            3\n",
      "Name: home_ownership, dtype: int64\n",
      "Not Verified       16281\n",
      "Verified           11856\n",
      "Source Verified     9538\n",
      "Name: verification_status, dtype: int64\n",
      "10+ years    8545\n",
      "< 1 year     4513\n",
      "2 years      4303\n",
      "3 years      4022\n",
      "4 years      3353\n",
      "5 years      3202\n",
      "1 year       3176\n",
      "6 years      2177\n",
      "7 years      1714\n",
      "8 years      1442\n",
      "9 years      1228\n",
      "Name: emp_length, dtype: int64\n",
      " 36 months    28234\n",
      " 60 months     9441\n",
      "Name: term, dtype: int64\n",
      "CA    6776\n",
      "NY    3614\n",
      "FL    2704\n",
      "TX    2613\n",
      "NJ    1776\n",
      "IL    1447\n",
      "PA    1442\n",
      "VA    1347\n",
      "GA    1323\n",
      "MA    1272\n",
      "OH    1149\n",
      "MD    1008\n",
      "AZ     807\n",
      "WA     788\n",
      "CO     748\n",
      "NC     729\n",
      "CT     711\n",
      "MI     678\n",
      "MO     648\n",
      "MN     581\n",
      "NV     466\n",
      "SC     454\n",
      "WI     427\n",
      "OR     422\n",
      "AL     420\n",
      "LA     420\n",
      "KY     311\n",
      "OK     285\n",
      "KS     249\n",
      "UT     249\n",
      "AR     229\n",
      "DC     209\n",
      "RI     194\n",
      "NM     180\n",
      "WV     164\n",
      "HI     162\n",
      "NH     157\n",
      "DE     110\n",
      "MT      77\n",
      "WY      76\n",
      "AK      76\n",
      "SD      60\n",
      "VT      53\n",
      "MS      19\n",
      "TN      17\n",
      "IN       9\n",
      "ID       6\n",
      "IA       5\n",
      "NE       5\n",
      "ME       3\n",
      "Name: addr_state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = ['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state']\n",
    "for c in cols:\n",
    "    print(loans[c].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The reason for the loan\n",
    "\n",
    "The `home_ownership`, `verification_status`, `emp_length`, `term`, and `addr_state` columns all contain multiple discrete values. \n",
    "\n",
    "We should clean the `emp_length` column and treat it as a numerical one since the values have ordering (2 years of employment is less than 8 years).\n",
    "\n",
    "First, let's look at the unique value counts for the `purpose` and `title` columns to understand which column we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debt Consolidation                                                       2068\n",
      "Debt Consolidation Loan                                                  1599\n",
      "Personal Loan                                                             624\n",
      "Consolidation                                                             488\n",
      "debt consolidation                                                        466\n",
      "                                                                         ... \n",
      "d.everett SOS",
      "Hail Mary Time! Double-down & we can score the WIN-WIN!       1\n",
      "GREAT BORROWER --DEBT CONSOLIDATION                                         1\n",
      "Debt consolidation & Refinancing                                            1\n",
      "2003 Mitsubishi Lancer                                                      1\n",
      "wek refinance                                                               1\n",
      "Name: title, Length: 18881, dtype: int64\n",
      "debt_consolidation    17751\n",
      "credit_card            4911\n",
      "other                  3711\n",
      "home_improvement       2808\n",
      "major_purchase         2083\n",
      "small_business         1719\n",
      "car                    1459\n",
      "wedding                 916\n",
      "medical                 655\n",
      "moving                  552\n",
      "house                   356\n",
      "vacation                348\n",
      "educational             312\n",
      "renewable_energy         94\n",
      "Name: purpose, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans[\"title\"].value_counts())\n",
    "print(loans[\"purpose\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Columns\n",
    "\n",
    "The home_ownership, verification_status, emp_length, and term columns each contain a few discrete categorical values. We should encode these columns as dummy variables and keep them.\n",
    "\n",
    "It seems like the purpose and title columns do contain overlapping information but we'll keep the purpose column since it contains a few discrete values. In addition, the title column has data quality issues since many of the values are repeated with slight modifications (e.g. Debt Consolidation and Debt Consolidation Loan and debt consolidation.\n",
    "\n",
    "We'll map the emp_length column to clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "loans = loans.drop([\"last_credit_pull_d\", \"earliest_cr_line\", \"addr_state\", \"title\"], axis=1)\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].str.rstrip(\"%\").astype(\"float\")\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].str.rstrip(\"%\").astype(\"float\")\n",
    "loans = loans.replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables\n",
    "\n",
    "Let's now encode the `home_ownership`, `verification_status`, `purpose`, and `term` columns as dummy variables so we can use them in our model. \n",
    "\n",
    "We first need to use the Pandas `get_dummies` method to return a new Dataframe containing a new column for each dummy variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "dummy_df = pd.get_dummies(loans[cat_columns])\n",
    "loans = pd.concat([loans, dummy_df], axis=1)\n",
    "loans = loans.drop(cat_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "Our eventual goal is to generate features from the data, which can feed into a machine learning algorithm. The algorithm will make predictions about whether or not a loan will be paid off on time, which is contained in the `loan_status` column of the clean dataset.\n",
    "\n",
    "We noticed that there's a class imbalance in our target column. There are about 6 times as many loans that were paid off on time (positive case, label of 1) than those that weren't (negative case, label of 0). \n",
    "\n",
    "Imbalances can cause issues with many machine learning algorithms, where they appear to have high accuracy, but actually aren't learning from the training data. Because of its potential to cause issues, we need to keep the class imbalance in mind as we build machine learning models.\n",
    "\n",
    "After all of our data cleaning in the past two missions, we ended up with the csv file called `cleaned_loans_2007.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37675 entries, 0 to 37674\n",
      "Data columns (total 38 columns):\n",
      "loan_amnt                              37675 non-null float64\n",
      "int_rate                               37675 non-null float64\n",
      "installment                            37675 non-null float64\n",
      "emp_length                             37675 non-null int64\n",
      "annual_inc                             37675 non-null float64\n",
      "loan_status                            37675 non-null int64\n",
      "dti                                    37675 non-null float64\n",
      "delinq_2yrs                            37675 non-null float64\n",
      "inq_last_6mths                         37675 non-null float64\n",
      "open_acc                               37675 non-null float64\n",
      "pub_rec                                37675 non-null float64\n",
      "revol_bal                              37675 non-null float64\n",
      "revol_util                             37675 non-null float64\n",
      "total_acc                              37675 non-null float64\n",
      "home_ownership_MORTGAGE                37675 non-null int64\n",
      "home_ownership_NONE                    37675 non-null int64\n",
      "home_ownership_OTHER                   37675 non-null int64\n",
      "home_ownership_OWN                     37675 non-null int64\n",
      "home_ownership_RENT                    37675 non-null int64\n",
      "verification_status_Not Verified       37675 non-null int64\n",
      "verification_status_Source Verified    37675 non-null int64\n",
      "verification_status_Verified           37675 non-null int64\n",
      "purpose_car                            37675 non-null int64\n",
      "purpose_credit_card                    37675 non-null int64\n",
      "purpose_debt_consolidation             37675 non-null int64\n",
      "purpose_educational                    37675 non-null int64\n",
      "purpose_home_improvement               37675 non-null int64\n",
      "purpose_house                          37675 non-null int64\n",
      "purpose_major_purchase                 37675 non-null int64\n",
      "purpose_medical                        37675 non-null int64\n",
      "purpose_moving                         37675 non-null int64\n",
      "purpose_other                          37675 non-null int64\n",
      "purpose_renewable_energy               37675 non-null int64\n",
      "purpose_small_business                 37675 non-null int64\n",
      "purpose_vacation                       37675 non-null int64\n",
      "purpose_wedding                        37675 non-null int64\n",
      "term_ 36 months                        37675 non-null int64\n",
      "term_ 60 months                        37675 non-null int64\n",
      "dtypes: float64(12), int64(26)\n",
      "memory usage: 10.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loans = pd.read_csv(\"cleaned_loans_2007.csv\")\n",
    "print(loans.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking an error metric\n",
    "\n",
    "Can we build a machine learning model that can accurately predict if a borrower will pay off their loan on time or not?\n",
    "\n",
    "We established that this is a binary classification problem in the first mission of this course, and we converted the `loan_status` column to `0`s and `1`s as a result. Before diving in and selecting an algorithm to apply to the data, we should select an error metric.\n",
    "\n",
    "We've generated some predictions automatically, and they are stored in a NumPy array called `predictions`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predict that all loans will be paid off on time.\n",
    "predictions = pd.Series(np.ones(loans.shape[0]))\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class imbalance\n",
    "\n",
    "optimize for:\n",
    "\n",
    " - high recall (true positive rate)\n",
    " - low fall-out (false positive rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "# Predict that all loans will be paid off on time.\n",
    "predictions = pd.Series(numpy.ones(loans.shape[0]))\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "A good first algorithm to apply to binary classification problems is logistic regression, for the following reasons:\n",
    "\n",
    " - it's quick to train and we can iterate more quickly,\n",
    " - it's less prone to overfitting than more complex models like decision trees,\n",
    " - it's easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otto/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "cols = loans.columns\n",
    "train_cols = cols.drop(\"loan_status\")\n",
    "features = loans[train_cols]\n",
    "target = loans[\"loan_status\"]\n",
    "lr.fit(features, target)\n",
    "predictions = lr.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "While we generated predictions in the last screen, those predictions were overfit. They were overfit because we generated predictions using the same data that we trained our model on.\n",
    "\n",
    "In order to get a realistic depiction of the accuracy of the model, let's perform `k-fold` cross validation. We can use the `cross_val_predict()` function from the `sklearn.model_selection` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otto/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9987920460880877\n",
      "0.9968454258675079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otto/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "lr = LogisticRegression()\n",
    "\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "# Rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalizing the classifier\n",
    "\n",
    "Even through we're not using accuracy as an error metric, the classifier is, and it isn't accounting for the imbalance in the classes. There are a few ways to get a classifier to correct for imbalanced classes. The two main ways are:\n",
    "\n",
    " - Use oversampling and undersampling to ensure that the classifier gets input that has a balanced number of each class.\n",
    " - Tell the classifier to penalize misclassifications of the less prevalent class more than the other class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otto/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/otto/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.567831258130459\n",
      "0.3802189645574318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otto/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual penalties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otto/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1830514774205538\n",
      "0.07812210057524586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otto/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9977079848850895\n",
      "0.9918352198923733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.cross_validation import cross_val_predict\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=1)\n",
    "predictions = cross_val_predict(rf, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.`\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Still quite a bit of room to improve:\n",
    "\n",
    " - We can tweak the penalties further.\n",
    " - We can try models other than a random forest and logistic regression.\n",
    " - We can use some of the columns we discarded to generate better features.\n",
    " - We can ensemble multiple models to get more accurate predictions.\n",
    " - We can tune the parameters of the algorithm to achieve higher performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Work with a data set of submissions to [Hacker News](https://news.ycombinator.com/)\n",
    "\n",
    "## Background\n",
    "\n",
    "Hacker News is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "We'll be examining two types of posts from Hacker News. `Ask HN` are posts that users submit to ask the Hacker News community a specific question. `Show HN` are posts by users to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "We'll compare `Ask HN` and `Show HN` to answer the following questions:\n",
    "\n",
    "    A. Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "    B. Do posts created at a certain time receive more comments on average?\n",
    "    C. Do either `Ask HN` or `Show HN` receive more points?\n",
    "    D. During which hours are the posts more likely to receive higher points?\n",
    "\n",
    "## Step 1: Opening and Exploring the Data\n",
    "\n",
    "You can find the data set at Kaggle [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "`id`: The unique identifier from Hacker News for the post\n",
    "`title`: The title of the post\n",
    "`url`: The URL that the posts links to, if it the post has a URL\n",
    "`num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "`num_comments`: The number of comments that were made on the post\n",
    "`author`: The username of the person who submitted the post\n",
    "`created_at`: The date and time at which the post was submitted\n",
    "\n",
    "Let's start by importing the libraries we need and reading the data set into a list of lists, `hn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "opened_file = open(\"hacker_news.csv\")\n",
    "from csv import reader\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a more readable table of the first rows of the data set:\n",
    "\n",
    "\n",
    "|id        | title   | url          | num_points | num_comments | author | created_at |\n",
    "|----------|---------|--------------|------------|--------------|--------|------------|\n",
    "|12224879 | Interactive Dynamic Video | http://www.interactivedynamicvideo.com/ | 386 | 52 | ne0phyte | 8/4/2016 11:52 | 10975351 | How to Use Open Source and Shut the Fuck Up at the Same Time | http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/ | 39 | 10 | josep2 | 1/26/2016 19:30 |\n",
    "| 11964716 | Florida DJs May Face Felony for April Fools' Water Joke | http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke | 63798/ | 2 | 1 | vezycash | 6/23/2016 22:20 |\n",
    "| 11919867 | Technology ventures: From Idea to Enterprise | https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429 | 3 | 1 | hswarna | 6/17/2016 0:01\n",
    "\n",
    "\n",
    "We notice that the first list in the inner lists contains the column headers, and the lists after contain the data for one row. \n",
    "\n",
    "## Step 2: In order to analyze our data, we'll remove the first row of column headers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've removed the headers from `hn`, we're ready to filter our data. Since we're only concerned with post titles beginning with `Ask HN` or `Show HN`, we'll create new lists of lists containing just the data for those titles.\n",
    "\n",
    "## Step 3: Filter our data to find the posts we're interested in\n",
    "\n",
    "To find the posts that begin with either `Ask HN` or `Show HN`, we'll use the string method `startswith`. Given a string object, say, `string1`, we can check if starts with, say, `dq` by inspecting the output of the object `string1.startswith('dq')`. If `string1` starts with `dq`, it will return `True`, otherwise it will return `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('dataquest'.startswith('Data'))\n",
    "print('dataquest'.startswith('data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, the first print call gives us `False` because `dataquest` does not start with `Data`. The second print call prints `True` because `dataquest` does start with `data`. Capitalization matters.\n",
    "\n",
    "If we wish to control for case, we can use the `lower` method which returns a lowercase version of the starting string. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataquest\n"
     ]
    }
   ],
   "source": [
    "print('DataQuest'.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use these methods to separate posts beginning with `Ask HN` and `Show HN` (and case variations) into two different lists next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ask posts: 1744\n",
      "Total number of show posts: 1162\n",
      "Total number of other posts: 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "    \n",
    "print(\"Total number of ask posts:\", len(ask_posts))\n",
    "print(\"Total number of show posts:\", len(show_posts))\n",
    "print(\"Total number of other posts:\", len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we separated the \"ask posts\" and the \"show posts\" into two list of lists named `ask_posts` and `show_posts`. \n",
    "\n",
    "We note that the majority of posts falls into the category of other posts. It might be of interest if we wanted to extend our sample to have a further look. For the moment, we will accept the results and work with our filtered data.\n",
    "\n",
    "Below are the first five rows for each of the list of lists `ask_posts` and `show_posts`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14'], ['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20'], ['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05'], ['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11'], ['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']]\n"
     ]
    }
   ],
   "source": [
    "print(show_posts[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Determine if ask posts or show posts receive more comments on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ask Comments:  14.038417431192661\n",
      "Average Show Comments:  10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "# Using list comprehension to tidy up the loops \n",
    "ask_comments = [int(row[4]) for row in ask_posts]\n",
    "show_comments = [int(row[4]) for row in show_posts]\n",
    "\n",
    "avg_ask_comments = sum(ask_comments)/len(ask_comments)\n",
    "avg_show_comments = sum(show_comments)/len(show_comments)\n",
    "\n",
    "print(\"Average Ask Comments: \",avg_ask_comments)\n",
    "print(\"Average Show Comments: \",avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer A: Our calculation indicates that on average, `ask hn` posts receive more comments. \n",
    "Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Determine if there is a certain time ask posts are more likely to attract comments. \n",
    "\n",
    "We'll use the following steps to perform this analysis:\n",
    "\n",
    "    1. Calculate the amount of ask posts in each hour of the day, along with the number of comments received.\n",
    "    2. Calculate the average number of comments ask posts received by hour created.\n",
    "\n",
    "We'll use `datetime` to work with the data in the `created_at` column. Note that the time data is EST, we'll use that information later to calculate the best time to create posts in our own timezone.\n",
    "\n",
    "Below, we'll create a two element list corresponding to the time data and comments. This will allow us to focus on the information necessary to build a frequency table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8/16/2016 9:55', 6],\n",
       " ['11/22/2015 13:43', 29],\n",
       " ['5/2/2016 10:14', 1],\n",
       " ['8/2/2016 14:20', 3]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    sublist = []\n",
    "    created_time = row[6]\n",
    "    comments = int(row[4])\n",
    "    sublist.append(created_time)\n",
    "    sublist.append(comments)\n",
    "    result_list.append(sublist)\n",
    "       \n",
    "result_list[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the frequency table with the date and comments data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n",
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n"
     ]
    }
   ],
   "source": [
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    dt_object = row[0]\n",
    "    dt_parsed = dt.datetime.strptime(dt_object, \"%m/%d/%Y %H:%M\")\n",
    "    hr = dt.datetime.strftime(dt_parsed,\"%H\")\n",
    "    #print(hr)\n",
    "    \n",
    "    if hr not in counts_by_hour:\n",
    "        counts_by_hour[hr] = 1\n",
    "        comments_by_hour[hr] = int(row[1])\n",
    "    else:\n",
    "        counts_by_hour[hr] = counts_by_hour[hr] + 1\n",
    "        comments_by_hour[hr] = comments_by_hour[hr] + int(row[1])\n",
    "\n",
    "print(comments_by_hour)\n",
    "print(counts_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Average number of comments in an hour\n",
    "\n",
    "We can now use these two dictionaries to calculate the average number of comments for posts created during each hour of the day. Below, we will build a list of lists containing the hours during which posts were created and the average number of comments those posts received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour,comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour    \n",
    "#1. lists can be created from dictionaries\n",
    "#2. Calculatons can be done on the key values of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. \n",
    "\n",
    "## Step 7: Sort the list of lists and print the five highest values so it's easier to read\n",
    "\n",
    "We'll swap the elements to display the average by hour below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    #print(key)\n",
    "    #creating a sublist and appending it\n",
    "    sublist = []\n",
    "    sublist.append(row[1])\n",
    "    sublist.append(row[0])\n",
    "    swap_avg_by_hour.append(sublist)\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the top 5 hours for posting comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Ask Posts Comments:\n",
      "\n",
      "    15:00: 38.59 average comments per post    \n",
      "    \n",
      "\n",
      "    02:00: 23.81 average comments per post    \n",
      "    \n",
      "\n",
      "    20:00: 21.52 average comments per post    \n",
      "    \n",
      "\n",
      "    16:00: 16.80 average comments per post    \n",
      "    \n",
      "\n",
      "    21:00: 16.01 average comments per post    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "#sorted function to arrange \n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print(\"Top 5 hours for Ask Posts Comments:\")\n",
    "\n",
    "for i in range(0,5):\n",
    "    hr_obj = dt.datetime.strptime(sorted_swap[i][1],\"%H\") # Assigns each value\n",
    "    hr_obj_string = dt.datetime.strftime(hr_obj, \"%H:%M\") #To final string\n",
    "    avg = sorted_swap[i][0]\n",
    "    template = '''\n",
    "    {}: {:.2f} average comments per post    \n",
    "    '''\n",
    "    print(template.format(hr_obj_string,avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer B: On average, the majority of comments are created at 15:00 EST.\n",
    "As previously noted, the above times are in EST (Eastern Standard Time). For my Central European Standard Time, I should post 7 hours ahead (depending on daylight savings time which is different for my time zone as well). So if I create posts at 22:00, 9:00, 3:00, 23:00, and 10:00 I will have the best chance for highest comment rate per hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Find out if either `Ask HN` or `Show HN` receive more points\n",
    "\n",
    "To know this, we will calculate the average number of points received by Ask and Show posts, in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of points received by all ask posts: 26268 \n",
      "Avg. number of points per ask post: 15.061926605504587 \n",
      "\n",
      "Total Number of points received by all show posts: 32019 \n",
      " Avg. number of points per show post: 27.555077452667813 \n",
      "\n",
      "On average, number of points received is greater for a show post.\n"
     ]
    }
   ],
   "source": [
    "a_points = 0\n",
    "s_points = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    a_points = a_points + int(row[3])\n",
    "\n",
    "print(\"Total Number of points received by all ask posts:\", a_points, \"\\n\"\n",
    "      \"Avg. number of points per ask post:\", (a_points/len(ask_posts)),\"\\n\")\n",
    "\n",
    "for row in show_posts:\n",
    "    s_points = s_points + int(row[3])\n",
    "\n",
    "print(\"Total Number of points received by all show posts:\", s_points,\"\\n\",\n",
    "      \"Avg. number of points per show post:\", (s_points/len(show_posts)),\"\\n\")\n",
    "\n",
    "if (a_points/len(ask_posts)) > (s_points/len(show_posts)):\n",
    "    print(\"On average, number of points received is greater for a an ask post.\")\n",
    "else:\n",
    "    print(\"On average, number of points received is greater for a show post.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer C: We've determined that `Show HN` posts receive more points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: During which hours are `Show HN` posts more likely to receive higher points\n",
    "\n",
    "As the average number of points per `Show HN` post is greater, we will continue our analysis on the times that they are most likely to receive higher points. \n",
    "\n",
    "As a refresher we will show the first 3 elements from our list of `show_posts` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05']]\n"
     ]
    }
   ],
   "source": [
    "print (show_posts[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now construct a list to hold the data we're interested in - similar to what we did previously for ask_posts in Step 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['11/25/2015 14:03', 26],\n",
       " ['11/29/2015 22:46', 747],\n",
       " ['4/28/2016 18:05', 1],\n",
       " ['7/28/2016 7:11', 3]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list_points_date = []\n",
    "\n",
    "for row in show_posts:\n",
    "    sublist = []\n",
    "    created_time = row[6]\n",
    "    points = int(row[3])\n",
    "    sublist.append(created_time)\n",
    "    sublist.append(points)\n",
    "    result_list_points_date.append(sublist)\n",
    "       \n",
    "result_list_points_date[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the frequency table with the date and posts data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14': 2187, '22': 1856, '18': 2215, '07': 494, '20': 1819, '05': 104, '16': 2634, '19': 1702, '15': 2228, '03': 679, '17': 2521, '06': 375, '02': 340, '13': 2438, '08': 519, '21': 866, '04': 386, '11': 1480, '12': 2543, '23': 1526, '09': 553, '01': 700, '10': 681, '00': 1173}\n",
      "{'14': 86, '22': 46, '18': 61, '07': 26, '20': 60, '05': 19, '16': 93, '19': 55, '15': 78, '03': 27, '17': 93, '06': 16, '02': 30, '13': 99, '08': 34, '21': 47, '04': 26, '11': 44, '12': 61, '23': 36, '09': 30, '01': 28, '10': 36, '00': 31}\n"
     ]
    }
   ],
   "source": [
    "show_counts_by_hour = {}\n",
    "points_by_hour = {}\n",
    "\n",
    "for row in result_list_points_date:\n",
    "    dt_obj = row[0]\n",
    "    dt_parsed = dt.datetime.strptime(dt_obj, \"%m/%d/%Y %H:%M\")\n",
    "    hr = dt.datetime.strftime(dt_parsed,\"%H\")\n",
    "    #print(hr)\n",
    "    \n",
    "    if hr not in show_counts_by_hour:\n",
    "        show_counts_by_hour[hr] = 1\n",
    "        points_by_hour[hr] = int(row[1])\n",
    "    else:\n",
    "        show_counts_by_hour[hr] = show_counts_by_hour[hr] + 1\n",
    "        points_by_hour[hr] = points_by_hour[hr] + int(row[1])\n",
    "\n",
    "print(points_by_hour)\n",
    "print(show_counts_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Average number of points for show post in any hour\n",
    "\n",
    "We can now use these two dictionaries for our calculation, very similar to Step 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['14', 25.430232558139537],\n",
       " ['22', 40.34782608695652],\n",
       " ['18', 36.31147540983606],\n",
       " ['07', 19.0],\n",
       " ['20', 30.316666666666666],\n",
       " ['05', 5.473684210526316],\n",
       " ['16', 28.322580645161292],\n",
       " ['19', 30.945454545454545],\n",
       " ['15', 28.564102564102566],\n",
       " ['03', 25.14814814814815],\n",
       " ['17', 27.107526881720432],\n",
       " ['06', 23.4375],\n",
       " ['02', 11.333333333333334],\n",
       " ['13', 24.626262626262626],\n",
       " ['08', 15.264705882352942],\n",
       " ['21', 18.425531914893618],\n",
       " ['04', 14.846153846153847],\n",
       " ['11', 33.63636363636363],\n",
       " ['12', 41.68852459016394],\n",
       " ['23', 42.388888888888886],\n",
       " ['09', 18.433333333333334],\n",
       " ['01', 25.0],\n",
       " ['10', 18.916666666666668],\n",
       " ['00', 37.83870967741935]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_avg_by_hour = []\n",
    "\n",
    "for hour in points_by_hour:\n",
    "    show_avg_by_hour.append([hour,points_by_hour[hour]/show_counts_by_hour[hour]])\n",
    "    \n",
    "show_avg_by_hour "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Sort the list of lists and print the five highest values so it's easier to read\n",
    "We'll swap the elements as in Step 7 and arrange them below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25.430232558139537, '14'], [40.34782608695652, '22'], [36.31147540983606, '18'], [19.0, '07'], [30.316666666666666, '20'], [5.473684210526316, '05'], [28.322580645161292, '16'], [30.945454545454545, '19'], [28.564102564102566, '15'], [25.14814814814815, '03'], [27.107526881720432, '17'], [23.4375, '06'], [11.333333333333334, '02'], [24.626262626262626, '13'], [15.264705882352942, '08'], [18.425531914893618, '21'], [14.846153846153847, '04'], [33.63636363636363, '11'], [41.68852459016394, '12'], [42.388888888888886, '23'], [18.433333333333334, '09'], [25.0, '01'], [18.916666666666668, '10'], [37.83870967741935, '00']]\n"
     ]
    }
   ],
   "source": [
    "swap_showavg_by_hour = []\n",
    "for row in show_avg_by_hour:\n",
    "    #print(key)\n",
    "    #creating a sublist and appending it\n",
    "    sublist = []\n",
    "    sublist.append(row[1])\n",
    "    sublist.append(row[0])\n",
    "    swap_showavg_by_hour.append(sublist)\n",
    "print(swap_showavg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Show Posts Points\n",
      "\n",
      "    23:00: 42.39 average points per post    \n",
      "    \n",
      "\n",
      "    12:00: 41.69 average points per post    \n",
      "    \n",
      "\n",
      "    22:00: 40.35 average points per post    \n",
      "    \n",
      "\n",
      "    00:00: 37.84 average points per post    \n",
      "    \n",
      "\n",
      "    18:00: 36.31 average points per post    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#sorted function to arrange \n",
    "show_sorted_swap = sorted(swap_showavg_by_hour, reverse = True)\n",
    "print(\"Top 5 hours for Show Posts Points\")\n",
    "\n",
    "for i in range(0,5):\n",
    "    hrobj = dt.datetime.strptime(show_sorted_swap[i][1],\"%H\") # Assigns what is what\n",
    "    hrobj_string = dt.datetime.strftime(hrobj, \"%H:%M\") #To final string\n",
    "    show_avg = show_sorted_swap[i][0]\n",
    "    template = '''\n",
    "    {}: {:.2f} average points per post    \n",
    "    '''\n",
    "    print(template.format(hrobj_string,show_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer D: The best time for a `show HN` post is at 23:00 EST.\n",
    "\n",
    "The times listed above are in Eastern Standard Time, so for Central European Time we'll advance 7 hours.\n",
    "\n",
    "6:00, 19:00, and 5:00 are the best times, followed by 7:00 and 1:00, to acquire the highest point totals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "To summarize our results:\n",
    "\n",
    "    A. Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "        ### Our calculation indicates that on average, `Ask HN` posts receive more comments (14 vs 10).\n",
    "    \n",
    "    B. Do posts created at a certain time receive more comments on average?\n",
    "        ### On average, the majority of comments are created at 15:00 EST.\n",
    "    \n",
    "    C. Do either `Ask HN` or `Show HN` receive more points?\n",
    "        ### `Show HN` posts receive more points (27 points vs. 15 for `Ask HN`)\n",
    "    \n",
    "    D. During which hours are the posts more likely to receive higher points?\n",
    "        ### The most points are received by posts created at 23:00, followed closely by those at 12:00 and 22:00.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

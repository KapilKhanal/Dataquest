{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See mission 6.5 ML Intermediate for more on the NBA players "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['player' 'pos' 'age' 'bref_team_id' 'g' 'gs' 'mp' 'fg' 'fga' 'fg.' 'x3p'\n",
      " 'x3pa' 'x3p.' 'x2p' 'x2pa' 'x2p.' 'efg.' 'ft' 'fta' 'ft.' 'orb' 'drb'\n",
      " 'trb' 'ast' 'stl' 'blk' 'tov' 'pf' 'pts' 'season' 'season_end']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nba = pd.read_csv(\"nba_2013.csv\")\n",
    "\n",
    "# The names of the columns in the data\n",
    "print(nba.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Similar Rows With Euclidean Distance\n",
    "\n",
    "selected_player = nba[nba[\"player\"] == \"LeBron James\"].iloc[0]\n",
    "distance_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts']\n",
    "\n",
    "import math\n",
    "def euclidean_distance(row):\n",
    "    inner_value = 0\n",
    "    for k in distance_columns:\n",
    "        inner_value += (row[k] - selected_player[k]) ** 2\n",
    "    return math.sqrt(inner_value)\n",
    "\n",
    "lebron_distance = nba.apply(euclidean_distance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Columns\n",
    "\n",
    "nba_numeric = nba[distance_columns]\n",
    "nba_normalized = (nba_numeric - nba_numeric.mean()) / nba_numeric.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carmelo Anthony\n"
     ]
    }
   ],
   "source": [
    "# Finding the Nearest Neighbor\n",
    "import pandas\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Fill in the NA values in nba_normalized\n",
    "nba_normalized.fillna(0, inplace=True)\n",
    "\n",
    "# Find the normalized vector for Lebron James\n",
    "lebron_normalized = nba_normalized[nba[\"player\"] == \"LeBron James\"]\n",
    "\n",
    "# Find the distance between Lebron James and everyone else.\n",
    "euclidean_distances = nba_normalized.apply(lambda row: distance.euclidean(row, lebron_normalized), axis=1)\n",
    "\n",
    "distance_frame = pandas.DataFrame(data={\"dist\": euclidean_distances, \"idx\": euclidean_distances.index})\n",
    "distance_frame.sort_values(\"dist\", inplace=True)\n",
    "second_smallest = distance_frame.iloc[1][\"idx\"]\n",
    "most_similar_to_lebron = nba.loc[int(second_smallest)][\"player\"]\n",
    "\n",
    "print(most_similar_to_lebron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Training and Testing Sets\n",
    "\n",
    "import random\n",
    "from numpy.random import permutation\n",
    "\n",
    "# Randomly shuffle the index of nba\n",
    "random_indices = permutation(nba.index)\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = math.floor(len(nba)/3)\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices\n",
    "test = nba.loc[random_indices[1:test_cutoff]]\n",
    "# Generate the train set with the rest of the data\n",
    "train = nba.loc[random_indices[test_cutoff:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of having to do it all ourselves, we can use the kNN implementation in scikit-learn. While scikit-learn (Sklearn for short) makes a regressor and a classifier available, we'll be using the regressor, as we have continuous values to predict on.\n",
    "\n",
    "Sklearn performs the normalization and distance finding automatically, and lets us specify how many neighbors we want to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "col_mask=nba.isnull().any(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_mask=nba.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg.</th>\n",
       "      <th>x3p.</th>\n",
       "      <th>x2p.</th>\n",
       "      <th>efg.</th>\n",
       "      <th>ft.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502703</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.611</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676737</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fg.      x3p.      x2p.   efg.    ft.\n",
       "1    0.503       NaN  0.502703  0.503  0.581\n",
       "2    0.520       NaN  0.520000  0.520  0.639\n",
       "5    0.541       NaN  0.540984  0.541  0.867\n",
       "11   0.500       NaN  0.500000  0.500  0.250\n",
       "18   0.375       NaN  0.375000  0.375  0.500\n",
       "..     ...       ...       ...    ...    ...\n",
       "456  0.500       NaN  0.500000  0.500    NaN\n",
       "460  0.000       NaN  0.000000  0.000    NaN\n",
       "461  0.000       NaN  0.000000  0.000    NaN\n",
       "468  0.556  0.333333  0.666667  0.611    NaN\n",
       "473  0.677       NaN  0.676737  0.677  0.726\n",
       "\n",
       "[78 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.loc[row_mask,col_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-2fb2363312b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Fit the model on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Make predictions on the test set using the fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \"\"\"\n\u001b[1;32m   1109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    737\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    740\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 562\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# The columns that we'll be using to make predictions\n",
    "x_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf']\n",
    "# The column we want to predict\n",
    "y_column = [\"pts\"]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Create the kNN model\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "# Fit the model on the training data\n",
    "knn.fit(train[x_columns], train[y_column])\n",
    "# Make predictions on the test set using the fit model\n",
    "predictions = knn.predict(test[x_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts    447605.646541\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array([[5.1900e+02],\n",
    "       [1.3560e+02],\n",
    "       [2.9720e+02],\n",
    "       [3.4460e+02],\n",
    "       [2.2800e+01],\n",
    "       [2.8240e+02],\n",
    "       [7.1400e+01],\n",
    "       [4.3040e+02],\n",
    "       [4.9380e+02],\n",
    "       [3.5340e+02],\n",
    "       [9.7440e+02],\n",
    "       [1.6920e+02],\n",
    "       [4.3780e+02],\n",
    "       [5.6460e+02],\n",
    "       [1.3014e+03],\n",
    "       [4.3520e+02],\n",
    "       [8.4320e+02],\n",
    "       [9.6400e+01],\n",
    "       [7.8300e+02],\n",
    "       [2.7600e+02],\n",
    "       [2.0760e+02],\n",
    "       [1.5620e+02],\n",
    "       [1.0200e+01],\n",
    "       [2.5100e+02],\n",
    "       [6.3580e+02],\n",
    "       [1.5102e+03],\n",
    "       [7.9200e+02],\n",
    "       [3.3940e+02],\n",
    "       [7.9800e+01],\n",
    "       [1.4612e+03],\n",
    "       [9.6400e+01],\n",
    "       [8.6600e+02],\n",
    "       [8.0440e+02],\n",
    "       [1.1048e+03],\n",
    "       [3.3680e+02],\n",
    "       [1.0678e+03],\n",
    "       [2.7180e+02],\n",
    "       [1.8170e+03],\n",
    "       [1.1434e+03],\n",
    "       [1.0542e+03],\n",
    "       [1.8000e+02],\n",
    "       [8.9600e+01],\n",
    "       [1.1160e+02],\n",
    "       [8.7800e+01],\n",
    "       [7.8160e+02],\n",
    "       [1.2780e+02],\n",
    "       [1.4100e+02],\n",
    "       [1.7886e+03],\n",
    "       [1.6500e+02],\n",
    "       [1.8140e+02],\n",
    "       [1.4238e+03],\n",
    "       [1.6020e+02],\n",
    "       [2.2200e+01],\n",
    "       [1.5600e+01],\n",
    "       [9.9460e+02],\n",
    "       [3.3320e+02],\n",
    "       [3.3100e+02],\n",
    "       [2.1880e+02],\n",
    "       [6.8200e+01],\n",
    "       [1.3292e+03],\n",
    "       [1.2000e+01],\n",
    "       [3.0000e+00],\n",
    "       [3.5340e+02],\n",
    "       [3.8120e+02],\n",
    "       [1.3292e+03],\n",
    "       [1.3020e+02],\n",
    "       [6.0300e+02],\n",
    "       [6.0200e+01],\n",
    "       [1.3828e+03],\n",
    "       [9.3100e+02],\n",
    "       [1.2314e+03],\n",
    "       [6.6660e+02],\n",
    "       [2.3440e+02],\n",
    "       [9.7060e+02],\n",
    "       [2.8460e+02],\n",
    "       [7.7020e+02],\n",
    "       [1.7886e+03],\n",
    "       [4.2000e+00],\n",
    "       [4.8980e+02],\n",
    "       [9.2360e+02],\n",
    "       [1.2200e+01],\n",
    "       [3.1380e+02],\n",
    "       [2.0040e+02],\n",
    "       [8.2400e+01],\n",
    "       [1.4704e+03],\n",
    "       [1.2200e+01],\n",
    "       [4.1000e+01],\n",
    "       [6.3800e+01],\n",
    "       [4.0200e+02],\n",
    "       [6.0000e-01],\n",
    "       [1.0520e+03],\n",
    "       [1.7760e+02],\n",
    "       [1.6000e+00],\n",
    "       [1.1056e+03],\n",
    "       [1.7840e+02],\n",
    "       [3.8680e+02],\n",
    "       [2.4960e+02],\n",
    "       [3.1020e+02],\n",
    "       [3.3860e+02],\n",
    "       [1.1640e+02],\n",
    "       [7.3220e+02],\n",
    "       [1.8440e+02],\n",
    "       [1.0720e+03],\n",
    "       [1.2300e+02],\n",
    "       [3.4800e+01],\n",
    "       [4.1620e+02],\n",
    "       [2.5200e+01],\n",
    "       [1.5960e+02],\n",
    "       [5.9000e+02],\n",
    "       [6.0260e+02],\n",
    "       [1.6842e+03],\n",
    "       [2.7160e+02],\n",
    "       [2.2600e+02],\n",
    "       [1.0036e+03],\n",
    "       [8.6000e+01],\n",
    "       [8.9200e+02],\n",
    "       [9.8000e+00],\n",
    "       [1.2000e+02],\n",
    "       [1.2000e+00],\n",
    "       [5.2400e+01],\n",
    "       [1.2828e+03],\n",
    "       [1.0160e+02],\n",
    "       [5.1420e+02],\n",
    "       [1.2456e+03],\n",
    "       [9.7200e+01],\n",
    "       [9.6400e+01],\n",
    "       [1.4400e+03],\n",
    "       [1.0976e+03],\n",
    "       [7.9560e+02],\n",
    "       [8.9600e+01],\n",
    "       [3.3200e+01],\n",
    "       [1.2736e+03],\n",
    "       [3.7880e+02],\n",
    "       [1.2086e+03],\n",
    "       [1.4400e+01],\n",
    "       [1.3078e+03],\n",
    "       [7.3000e+01],\n",
    "       [5.9980e+02],\n",
    "       [1.1052e+03],\n",
    "       [2.8440e+02],\n",
    "       [5.3820e+02],\n",
    "       [4.6120e+02],\n",
    "       [7.1400e+01],\n",
    "       [1.7840e+02],\n",
    "       [1.0586e+03],\n",
    "       [1.3292e+03],\n",
    "       [9.9400e+01],\n",
    "       [1.5272e+03],\n",
    "       [3.4400e+02],\n",
    "       [2.9440e+02],\n",
    "       [5.9380e+02],\n",
    "       [1.0800e+02],\n",
    "       [6.0900e+02],\n",
    "       [6.8220e+02],\n",
    "       [3.5600e+01],\n",
    "       [2.9860e+02],\n",
    "       [9.4200e+01],\n",
    "       [9.8500e+02],\n",
    "       [1.0618e+03]])\n",
    "\n",
    "actual = test[y_column]\n",
    "mse = (((predictions - actual) ** 2).sum()) / len(predictions)\n",
    "\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-daf2f47b1aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "# Splitting the Data into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(nba[\"pts\"], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-fcd0f3201953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# making predictions with fit\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

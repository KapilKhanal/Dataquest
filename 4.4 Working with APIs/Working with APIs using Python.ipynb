{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past few missions, we learned how to make API requests, authenticate with an API server, and parse responses. In this challenge, you'll pull these concepts together to explore trending posts and comments on reddit.\n",
    "\n",
    "Reddit is a community-driven link-sharing site. Users submit links to articles, photos, and other content. Other users upvote the submissions they like, and downvote the ones they dislike. Users can comment on submissions, and even upvote or downvote other people's comments.\n",
    "\n",
    "Reddit consists of many smaller communities called subreddits where more focused communities can discuss niche posts. For example, /r/python is a Python-focused community, and /r/sanfrancisco is for discussing issues relating to the city of San Francisco, CA. The posts you submit to a subreddit will appear on the group's front page if enough users upvote them. Very popular subreddit posts may appear on reddit's home page.\n",
    "\n",
    "Posts only stay on the main reddit and subreddit pages for a limited time. You can search for older posts, but it can be hard to find what you're looking for.\n",
    "\n",
    "In this challenge, you'll practice:\n",
    "\n",
    " - Retrieving a list of trending posts on a particular subreddit\n",
    " - Exploring the comments on a single article\n",
    " - Posting our own comment on an article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Tokens are revoked and don't work except through the DQ platform\n",
    "\n",
    "The reddit API requires authentication. You authenticated with a token in a previous mission, but in this challenge, you'll use `OAuth`. OAuth can be fairly complex, but we've done some of the hard work already. You'll be using an authentication token, `13426216-4U1ckno9J5AiK72VRbpEeBaMSKk`, to authenticate in much the same way we did earlier, except that the header will look like this:\n",
    "\n",
    "`{\"Authorization\": \"bearer 13426216-4U1ckno9J5AiK72VRbpEeBaMSKk\"}`\n",
    "Note that we'll need to use the string bearer instead of the string token we used in the previous mission. That's because we're using OAuth this time. While we won't discuss OAuth right now, you can read about it on Wikipedia and through this blog post.\n",
    "\n",
    "We'll also need to add a `User-Agent` header, which will identify us as `Dataquest` to the API:\n",
    "`\n",
    "{\"Authorization\": \"bearer 13426216-4U1ckno9J5AiK72VRbpEeBaMSKk\", \"User-Agent\": \"Dataquest/1.0\"}`\n",
    "\n",
    "Steps: \n",
    " - Retrieve the /r/python subreddit's top posts for the past day.\n",
    " \n",
    "   - Make a GET request to https://oauth.reddit.com/r/python/top using the get method of the requests library. See the documentation for the /r/python/top endpoint if you need help.\n",
    "   \n",
    "   - Pass in the header information we showed you earlier in this section.\n",
    "   \n",
    "   - To retrieve only the top posts for the past day, pass in a query parameter t (for \"time\") and set its value to the string day.\n",
    "   \n",
    " - Use the json method on the response to get the JSON response data.\n",
    " \n",
    " - Assign the JSON response data to the variable python_top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Unauthorized', 'error': 401}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"Authorization\": \"bearer 13426216-4U1ckno9J5AiK72VRbpEeBaMSKk\", \"User-Agent\": \"Dataquest/1.0\"}\n",
    "params = {\"t\": \"day\"}\n",
    "response = requests.get(\"https://oauth.reddit.com/r/python/top\", headers=headers, params=params)\n",
    "\n",
    "python_top = response.json()\n",
    "print(python_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable python_top is a dictionary containing information about all of the individual posts that users submitted during the past day. However, the actual list of posts is buried inside a dictionary key, and you'll need to explore the dictionary to retrieve it. You can read more about `python_top's` format here: https://old.reddit.com/dev/api#listings\n",
    "\n",
    "There's a dictionary for each individual post that looks like this:\n",
    "\n",
    "`{'data': {'approved_by': None,\n",
    "     'archived': False,\n",
    "     'author': 'ingvij',\n",
    "     ...\n",
    "     'ups': 43,\n",
    "     'url': 'http://hkupty.github.io/2016/Functional-Programming-Concepts-Idioms-and-Philosophy/',\n",
    "     'user_reports': [],\n",
    "     'visited': False},\n",
    "     'kind': 't3'}`\n",
    "     \n",
    "We've truncated the representation, but you can see the `ups` field, which contains the number of people who upvoted the post. The id field holds reddit's unique ID for the post.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the most upvoted post\n",
    "\n",
    " - Explore the python_top dictionary.\n",
    " - Extract the list containing all of the posts, and assign it to python_top_articles.\n",
    " - Find the post with the most upvotes.\n",
    " - Assign the ID for the post with the most upvotes to most_upvoted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e3a16a1839ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpython_top_articles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_top\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"children\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmost_upvoted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmost_upvotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpython_top_articles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "python_top_articles = python_top[\"data\"][\"children\"]\n",
    "most_upvoted = \"\"\n",
    "most_upvotes = 0\n",
    "for article in python_top_articles:\n",
    "    ar = article[\"data\"]\n",
    "    if ar[\"ups\"] >= most_upvotes:\n",
    "        most_upvoted = ar[\"id\"]\n",
    "        most_upvotes = ar[\"ups\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting post comments\n",
    "\n",
    " - Get all of the comments on the /r/python subreddit's top post from the past day.\n",
    " - Generate the full URL to query, using the subreddit name and post ID.\n",
    " - Make a GET request to the URL.\n",
    " - Get the response data using the response's json method.\n",
    " - Assign the response data to the variable comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": \"bearer 13426216-4U1ckno9J5AiK72VRbpEeBaMSKk\", \"User-Agent\": \"Dataquest/1.0\"}\n",
    "response = requests.get(\"https://oauth.reddit.com/r/python/comments/4b7w9u\", headers=headers)\n",
    "\n",
    "comments = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the most upvoted comment\n",
    "\n",
    " - Find the most upvoted top-level comment in comments.\n",
    " - Extract the comments list from the comments variable, and assign it to comments_list.\n",
    " - Assign the ID for the comment with the most upvotes to most_upvoted_comment.\n",
    " \n",
    " Sample code: \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fe6f1aa2f4c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomments_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"children\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmost_upvoted_comment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmost_upvotes_comment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomments_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "comments_list = comments[1][\"data\"][\"children\"]\n",
    "most_upvoted_comment = \"\"\n",
    "most_upvotes_comment = 0\n",
    "for comment in comments_list:\n",
    "    co = comment[\"data\"]\n",
    "    if co[\"ups\"] >= most_upvotes_comment:\n",
    "        most_upvoted_comment = co[\"id\"]\n",
    "        most_upvotes_comment = co[\"ups\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upvoting a comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"dir\": 1, \"id\": \"d16y4ry\"}\n",
    "headers = {\"Authorization\": \"bearer 13426216-4U1ckno9J5AiK72VRbpEeBaMSKk\", \"User-Agent\": \"Dataquest/1.0\"}\n",
    "response = requests.post(\"https://oauth.reddit.com/api/vote\", json=payload, headers=headers)\n",
    "status = response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
